{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c313a9-54a2-4f66-8465-31cee2fa875a",
   "metadata": {},
   "source": [
    "# Calculate Percentage of Different Severities of Drought using SPI; AGCD and CORDEX Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8097a-5103-4b70-bb11-3f26e54159b0",
   "metadata": {},
   "source": [
    "Using drought thresholds as defined in McKee et al. (1993): https://www.droughtmanagement.info/literature/AMS_Relationship_Drought_Frequency_Duration_Time_Scales_1993.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf2851-f5b4-4ae3-a777-d2353151e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "%matplotlib inline\n",
    "%run /g/data/w40/ri9247/code/aus_precip_benchmarking/master_functions_bmf.ipynb\n",
    "import fnmatch\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da9e47-1dfe-4597-b096-78ee7c99be97",
   "metadata": {},
   "source": [
    "## Define Spatiotemporal Boundaries and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc0b51-5e0a-4c23-836e-03bf34ad34dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define region of interest (lat and lon boundaries for all of Australia)\n",
    "lat_slice = slice(-44.5,-10)\n",
    "lon_slice = slice(112,156.25)\n",
    "time_slice = slice(\"1976-01-01\", \"2005-12-30\")\n",
    "\n",
    "# Define temporal scale for SPI variable (1 for 3-months, 2 for 6-months, 3 for 12-months); use \"None\" if not using the SPI variable\n",
    "#iscale = 2\n",
    "\n",
    "# Define a list for all iscale values to calculate SPI at each SPI averaging period\n",
    "iscale_list = [1,2,3]\n",
    "\n",
    "# Define season as a list of month numbers. If no seasonal breakdown, use None.\n",
    "season = None \n",
    "season_name = 'Annual' \n",
    "\n",
    "# Path to combined quality mask\n",
    "qc_mask_ds = xr.open_dataset('/g/data/w40/ri9247/CORDEX-Australasia/data/obs/AUS-44i_grid/no_indices/mask/AUS-44i_combined_quality_mask_no_oceans.nc')\n",
    "\n",
    "# Extract mask over Australia\n",
    "qc_mask = qc_mask_ds.station_mask.sel(lat=lat_slice, lon=lon_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942eb0bd-2f3e-4e1d-98bf-c0c637df9031",
   "metadata": {},
   "source": [
    "## Define Keywords for Data and Data Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07e176-522b-44db-887e-b7e5cc2d639f",
   "metadata": {},
   "source": [
    "Keywords needed are bracketed {}. <br><br>\n",
    "**RCM** database is organized following: <br>\n",
    "**Climpact Indices:** <br>\n",
    "parent_directory/{time_period}/{index-keyword}/{variable}_{time_average} _dataset_file.nc \n",
    "<br><br>\n",
    "**Observations** database is organized as follows: <br>\n",
    "obs_parent_directory/grid_type}/climpact/{variable}/{variable} _{time_average}_agcd_historical_v1_1950-2020.nc <br><br>\n",
    "**Keyword Options:** <br>\n",
    "grid_type: 'AUS-44i_grid', 'native_grid', 'one_degree_grid' <br>\n",
    "time_period: 'historical', 'rcp85' <br>\n",
    "variable: See list of Climpact Indices at: https://climpact-sci.org/indices; must be all-lowercase <br>\n",
    "time_average: 'ANN', 'MON'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7080e9-cb94-4018-98ff-b8aa1beaf8e1",
   "metadata": {},
   "source": [
    "### Using Climpact Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a610c3-d9bf-4442-91c1-4f3ee973e37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define keywords to be used with f-strings to build the path to datasets\n",
    "time_period = 'historical'\n",
    "variable = 'spi'\n",
    "time_average = 'MON'\n",
    "grid_type = 'AUS-44i_grid'\n",
    "\n",
    "# Define paths to data\n",
    "model_master_path = '/g/data/ks32/CLEX_Data/CORDEX_Australasia_Indices/v1-0/'\n",
    "obs_master_path = '/g/data/w40/ri9247/CORDEX-Australasia/data/obs/'\n",
    "\n",
    "model_data_path = model_master_path + f'{time_period}/{variable}/'\n",
    "agcd_data_path = obs_master_path + f'{grid_type}/climpact/{variable}/{variable}_{time_average}_agcd_historical_v1_1950-2020.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee41fe-8fd0-4d03-9e87-ab81523a19cc",
   "metadata": {},
   "source": [
    "## Define list for subset of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16784db8-7dcf-4386-90eb-80fbe03edf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List names of model subsets. This is dependent on model performance against the Minimum Standards Metrics and will need to be updated for other applications\n",
    "subset_names = [\n",
    "    \"ACCESS1-0   CCAM-1704\"\n",
    "    , \"ACCESS1-0   CCAM-2008\"\n",
    "    , \"ACCESS1-0   WRF360J\"\n",
    "    , \"ACCESS1-0   WRF360K\"\n",
    "    , \"CanESM2   CCAM-2008\"\n",
    "    , \"CanESM2   WRF360J\"\n",
    "    , \"CNRM-CM5   CCAM-1704\"\n",
    "    , \"GFDL-ESM2M   CCAM-1704\"\n",
    "    , \"GFDL-ESM2M   CCAM-2008\"\n",
    "    , \"HadGEM2-CC   CCAM-1704\"\n",
    "    , \"HadGEM2-ES   CCLM5-0-15\"\n",
    "    , \"HadGEM2-ES   REMO2015\"\n",
    "    , \"MIROC5   CCAM-1704\"\n",
    "    , \"MIROC5   CCAM-2008\"\n",
    "    , \"MPI-ESM-LR   CCLM5-0-15\"\n",
    "    , \"MPI-ESM-LR   REMO2015\"\n",
    "    , \"MPI-ESM-MR   RegCM4-7\"\n",
    "    , \"NorESM1-M   CCAM-1704\"\n",
    "    , \"NorESM1-M   RegCM4-7\"\n",
    "    , \"NorESM1-M   REMO2015\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df002e-6ff2-4278-a950-070a4187845c",
   "metadata": {},
   "source": [
    "## Get Data File Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60519bd6-4ab1-436e-bd86-24a7b97879b8",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525e1f5-b199-43d0-b962-9196c1ac9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all model paths in full ensemble (this will be stored in a Pandas DataFrame)\n",
    "model_paths = get_model_files(model_data_path, time_average)\n",
    "\n",
    "# Get file paths for subset of models\n",
    "model_paths_subset = get_model_files_subset(model_paths, subset_names)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Option to print paths to confirm we get the correct files\n",
    "model_paths_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adff227-7f5a-4262-800e-0faf76996cf9",
   "metadata": {},
   "source": [
    "## Get Weighted Spatial Average for each SPI Temporal Interval at Each Time Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5247f8-3f7a-4791-94da-8c140dc76e0d",
   "metadata": {},
   "source": [
    "#### Obs - AGCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9330ff4-df89-4ea6-9d02-907752c0bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionary to store Obs time series of SPI at different time intervals\n",
    "obs_ts_dict = {}\n",
    "\n",
    "# Loop through iscale list and calculate time series for each iscale value for the observational dataset\n",
    "for iscale in iscale_list:\n",
    "    \n",
    "    obs_ts = get_weighted_spatial_average_at_default_time_step(agcd_data_path, variable, time_slice, lat_slice, lon_slice, season, iscale, qc_mask)\n",
    "    \n",
    "    # Define dictionary keys based on the temporal interval of the SPI calculation (1 for 3-months, 2 for 6-months, 3 for 12-months)\n",
    "    if iscale == 1:\n",
    "        obs_ts_dict['obs_3mon'] = obs_ts\n",
    "        \n",
    "    elif iscale == 2:\n",
    "        obs_ts_dict['obs_6mon'] = obs_ts\n",
    "        \n",
    "    elif iscale == 3:\n",
    "        obs_ts_dict['obs_12mon'] = obs_ts\n",
    "\n",
    "# Option to print dictionary keys\n",
    "#print(obs_ts_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d6919-dd42-4b5b-8225-bc0a36f4ea2e",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3bc76-d319-48f5-94e6-1bbc4589d420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Intialize empty dictionaries to store model timeseries SPI at different time intervals\n",
    "model_3mon_ts_dict = {}\n",
    "model_6mon_ts_dict = {}\n",
    "model_12mon_ts_dict = {}\n",
    "\n",
    "# Loop through iscale list and calculate time series for each iscale value for each model dataset\n",
    "for iscale in iscale_list:\n",
    "    \n",
    "    # Loop through RCM simulations; store time series in appropriate dictionaries\n",
    "    for i, row in model_paths_subset.iterrows():\n",
    "    \n",
    "        # Get weighted spatial average for time series\n",
    "        model_ts = get_weighted_spatial_average_at_default_time_step(model_paths_subset.iloc[i,1], variable, time_slice, lat_slice, lon_slice, season, iscale, qc_mask)\n",
    "    \n",
    "        # Add to appropriate dictionary based on the temporal interval of the SPI calculation (1 for 3-months, 2 for 6-months, 3 for 12-months)\n",
    "        if iscale == 1:\n",
    "            model_3mon_ts_dict[model_paths_subset.iloc[i,0]] = model_ts\n",
    "        \n",
    "        elif iscale == 2:\n",
    "            model_6mon_ts_dict[model_paths_subset.iloc[i,0]] = model_ts\n",
    "        \n",
    "        elif iscale == 3:\n",
    "            model_12mon_ts_dict[model_paths_subset.iloc[i,0]] = model_ts\n",
    "\n",
    "# Option to print dictionary keys for one dictionary\n",
    "print(model_12mon_ts_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f2e5ec-cfbb-4f72-b917-7b6e26b9370c",
   "metadata": {},
   "source": [
    "## Calculate Percentage of Each Category of Drought across the time series (McKee et al. 1993)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4779957a-815e-404f-9c59-6218af4641bf",
   "metadata": {},
   "source": [
    "### Define specific thresholds for drought categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336062b-ce09-4592-af8c-ea20736ec595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list for categories of drought\n",
    "#drought_cats = ['mild', 'moderate', 'severe', 'extreme'] # McKee et al 1993 categories\n",
    "drought_cats = ['moderate', 'severe', 'extreme'] # WMO 2012 categories\n",
    "\n",
    "# Define thresholds for categories of drought\n",
    "# No min value for 'extreme' category: anything under -2.00\n",
    "\n",
    "#mild_max = 0\n",
    "#mild_min = -0.99\n",
    "\n",
    "moderate_max = -1.00\n",
    "moderate_min = -1.49\n",
    "\n",
    "severe_max = -1.50\n",
    "severe_min = -1.99\n",
    "\n",
    "extreme_max = -2.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53196488-c4ac-4060-8bb8-5d317de6dd69",
   "metadata": {},
   "source": [
    "### Obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d8a7a-7fdb-4d33-96da-1a737ef4468b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Pandas DataFrame to store percentage of time series in each category of drought\n",
    "obs_master_drought_df = pd.DataFrame(columns=['dataset_name', 'moderate', 'severe', 'extreme'])\n",
    "\n",
    "# Loop through each observational time series\n",
    "for obs_ts in obs_ts_dict.keys():\n",
    "    \n",
    "    # Loop through each drought category and calculate percentage of time series in that category of drought\n",
    "    for drought_type in drought_cats:\n",
    "        \n",
    "        #if drought_type == 'mild':\n",
    "        #    obs_perc_mild = ((obs_ts_dict[obs_ts] >= mild_min) & (obs_ts_dict[obs_ts] <= mild_max)).mean() * 100\n",
    "            \n",
    "        if drought_type == 'moderate':\n",
    "            obs_perc_moderate = ((obs_ts_dict[obs_ts] >= moderate_min) & (obs_ts_dict[obs_ts] <= moderate_max)).mean() * 100\n",
    "        \n",
    "        elif drought_type == 'severe':\n",
    "            obs_perc_severe = ((obs_ts_dict[obs_ts] >= severe_min) & (obs_ts_dict[obs_ts] <= severe_max)).mean() * 100\n",
    "            \n",
    "        elif drought_type == 'extreme':\n",
    "            obs_perc_extreme = ((obs_ts_dict[obs_ts] <= extreme_max)).mean() * 100\n",
    "            \n",
    "    # Create Pandas DataFrame for each obs_ts\n",
    "    obs_percentage_df = pd.DataFrame({'dataset_name': f'{obs_ts}', 'moderate': obs_perc_moderate.item(0), 'severe': obs_perc_severe.item(0), 'extreme': obs_perc_extreme.item(0)}, index=[0])\n",
    "   \n",
    "    # Add obs dataframe to master obs DataFrame\n",
    "    obs_master_drought_df = pd.concat([obs_master_drought_df, obs_percentage_df], ignore_index=True)\n",
    "    \n",
    "# print obs master dataframe\n",
    "obs_master_drought_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840950c5-9b29-475e-8686-baf301ecdd2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Models\n",
    "Calculate percentage of time series in each drought category separately based on SPI averaging period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f599bc-b925-4563-b281-b4b02f4fbb70",
   "metadata": {},
   "source": [
    "### 3-Month SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e409767-e222-40f1-ad7b-f06091810c49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3-Month SPI \n",
    "\n",
    "# Initialize Pandas DataFrame to store percentage of time series in each category of drought\n",
    "model_3mon_master_drought_df = pd.DataFrame(columns=['dataset_name', 'moderate', 'severe', 'extreme'])\n",
    "\n",
    "# Loop through each model time series\n",
    "for model_ts in model_3mon_ts_dict.keys():\n",
    "    \n",
    "    # Loop through each drought category and calculate percentage of time series in that category of drought\n",
    "    for drought_type in drought_cats:\n",
    "        \n",
    "        #if drought_type == 'mild':\n",
    "        #    model_perc_mild = ((model_3mon_ts_dict[model_ts] >= mild_min) & (model_3mon_ts_dict[model_ts] <= mild_max)).mean() * 100\n",
    "            \n",
    "        if drought_type == 'moderate':\n",
    "            model_perc_moderate = ((model_3mon_ts_dict[model_ts] >= moderate_min) & (model_3mon_ts_dict[model_ts] <= moderate_max)).mean() * 100\n",
    "        \n",
    "        elif drought_type == 'severe':\n",
    "            model_perc_severe = ((model_3mon_ts_dict[model_ts] >= severe_min) & (model_3mon_ts_dict[model_ts] <= severe_max)).mean() * 100\n",
    "            \n",
    "        elif drought_type == 'extreme':\n",
    "            model_perc_extreme = ((model_3mon_ts_dict[model_ts] <= extreme_max)).mean() * 100\n",
    "            \n",
    "    # Create Pandas DataFrame for each model_ts\n",
    "    #model_percentage_df = pd.DataFrame({'dataset_name': f'{model_ts}', 'mild': model_perc_mild.item(0), 'moderate': model_perc_moderate.item(0), 'severe': model_perc_severe.item(0), 'extreme': model_perc_extreme.item(0)}, index=[0])\n",
    "    model_percentage_df = pd.DataFrame({'dataset_name': f'{model_ts}', 'moderate': model_perc_moderate.item(0), 'severe': model_perc_severe.item(0), 'extreme': model_perc_extreme.item(0)}, index=[0])\n",
    "   \n",
    "    # Add model dataframe to master model DataFrame\n",
    "    model_3mon_master_drought_df = pd.concat([model_3mon_master_drought_df, model_percentage_df], ignore_index=True)\n",
    "    \n",
    "# print master dataframe\n",
    "model_3mon_master_drought_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0bf55-5d39-4667-b378-0e955c697310",
   "metadata": {},
   "source": [
    "### 6-Month SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88809dc3-26ae-465a-9c82-67cfc9e1e0f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6-Month SPI\n",
    "\n",
    "# Initialize Pandas DataFrame to store percentage of time series in each category of drought\n",
    "model_6mon_master_drought_df = pd.DataFrame(columns=['dataset_name', 'moderate', 'severe', 'extreme'])\n",
    "\n",
    "# Loop through each model time series\n",
    "for model_ts in model_6mon_ts_dict.keys():\n",
    "    \n",
    "    # Loop through each drought category and calculate percentage of time series in that category of drought\n",
    "    for drought_type in drought_cats:\n",
    "        \n",
    "        #if drought_type == 'mild':\n",
    "        #    model_perc_mild = ((model_6mon_ts_dict[model_ts] >= mild_min) & (model_6mon_ts_dict[model_ts] <= mild_max)).mean() * 100\n",
    "            \n",
    "        if drought_type == 'moderate':\n",
    "            model_perc_moderate = ((model_6mon_ts_dict[model_ts] >= moderate_min) & (model_6mon_ts_dict[model_ts] <= moderate_max)).mean() * 100\n",
    "        \n",
    "        elif drought_type == 'severe':\n",
    "            model_perc_severe = ((model_6mon_ts_dict[model_ts] >= severe_min) & (model_6mon_ts_dict[model_ts] <= severe_max)).mean() * 100\n",
    "            \n",
    "        elif drought_type == 'extreme':\n",
    "            model_perc_extreme = ((model_6mon_ts_dict[model_ts] <= extreme_max)).mean() * 100\n",
    "            \n",
    "    # Create Pandas DataFrame for each model_ts\n",
    "    #model_percentage_df = pd.DataFrame({'dataset_name': f'{model_ts}', 'mild': model_perc_mild.item(0), 'moderate': model_perc_moderate.item(0), 'severe': model_perc_severe.item(0), 'extreme': model_perc_extreme.item(0)}, index=[0])\n",
    "    model_percentage_df = pd.DataFrame({'dataset_name': f'{model_ts}', 'moderate': model_perc_moderate.item(0), 'severe': model_perc_severe.item(0), 'extreme': model_perc_extreme.item(0)}, index=[0])\n",
    "   \n",
    "    # Add model dataframe to master model DataFrame\n",
    "    model_6mon_master_drought_df = pd.concat([model_6mon_master_drought_df, model_percentage_df], ignore_index=True)\n",
    "    \n",
    "# print master dataframe\n",
    "model_6mon_master_drought_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea83381-be09-42c6-b37f-a01f6795d449",
   "metadata": {},
   "source": [
    "### 12-Month SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3acd5f-a5a5-4be7-bd88-ab7e73254bbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 12-Month SPI\n",
    "\n",
    "# Initialize Pandas DataFrame to store percentage of time series in each category of drought\n",
    "model_12mon_master_drought_df = pd.DataFrame(columns=['dataset_name', 'moderate', 'severe', 'extreme'])\n",
    "\n",
    "# Loop through each model time series\n",
    "for model_ts in model_12mon_ts_dict.keys():\n",
    "    \n",
    "    # Loop through each drought category and calculate percentage of time series in that category of drought\n",
    "    for drought_type in drought_cats:\n",
    "        \n",
    "        #if drought_type == 'mild':\n",
    "        #    model_perc_mild = ((model_12mon_ts_dict[model_ts] >= mild_min) & (model_12mon_ts_dict[model_ts] <= mild_max)).mean() * 100\n",
    "            \n",
    "        if drought_type == 'moderate':\n",
    "            model_perc_moderate = ((model_12mon_ts_dict[model_ts] >= moderate_min) & (model_12mon_ts_dict[model_ts] <= moderate_max)).mean() * 100\n",
    "        \n",
    "        elif drought_type == 'severe':\n",
    "            model_perc_severe = ((model_12mon_ts_dict[model_ts] >= severe_min) & (model_12mon_ts_dict[model_ts] <= severe_max)).mean() * 100\n",
    "            \n",
    "        elif drought_type == 'extreme':\n",
    "            model_perc_extreme = ((model_12mon_ts_dict[model_ts] <= extreme_max)).mean() * 100\n",
    "            \n",
    "    # Create Pandas DataFrame for each model_ts\n",
    "    model_percentage_df = pd.DataFrame({'dataset_name': f'{model_ts}', 'moderate': model_perc_moderate.item(0), 'severe': model_perc_severe.item(0), 'extreme': model_perc_extreme.item(0)}, index=[0])\n",
    "   \n",
    "    # Add model dataframe to master model DataFrame\n",
    "    model_12mon_master_drought_df = pd.concat([model_12mon_master_drought_df, model_percentage_df], ignore_index=True)\n",
    "    \n",
    "# print master dataframe\n",
    "model_12mon_master_drought_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ac4fa-02a1-4c20-8a68-1f169306ae81",
   "metadata": {},
   "source": [
    "## Plot Time series and fill areas that fall within threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7c9b2-f595-4e99-949c-d3179f7fb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dataset names for subset of models - alphabatized for plotting\n",
    "\n",
    "# Alphabetized by forcing GCM (Obs first)\n",
    "dataset_names = [\n",
    "    \"AGCD\"\n",
    "    ,\"ACCESS1-0   CCAM-1704\"\n",
    "    , \"ACCESS1-0   CCAM-2008\"\n",
    "    , \"ACCESS1-0   WRF360J\"\n",
    "    , \"ACCESS1-0   WRF360K\"\n",
    "    , \"CanESM2   CCAM-2008\"\n",
    "    , \"CanESM2   WRF360J\"\n",
    "    , \"CNRM-CM5   CCAM-1704\"\n",
    "    , \"GFDL-ESM2M   CCAM-1704\"\n",
    "    , \"GFDL-ESM2M   CCAM-2008\"\n",
    "    , \"HadGEM2-CC   CCAM-1704\"\n",
    "    , \"HadGEM2-ES   CCLM5-0-15\"\n",
    "    , \"HadGEM2-ES   REMO2015\"\n",
    "    , \"MIROC5   CCAM-1704\"\n",
    "    , \"MIROC5   CCAM-2008\"\n",
    "    , \"MPI-ESM-LR   CCLM5-0-15\"\n",
    "    , \"MPI-ESM-LR   REMO2015\"\n",
    "    , \"MPI-ESM-MR   RegCM4-7\"\n",
    "    , \"NorESM1-M   CCAM-1704\"\n",
    "    , \"NorESM1-M   RegCM4-7\"\n",
    "    , \"NorESM1-M   REMO2015\"\n",
    "]\n",
    "\n",
    "# Alphabetized by RCM to match the organization of the tables in the paper\n",
    "dataset_names_rcm_sorted = [\n",
    "    \"AGCD\"\n",
    "    , \"ACCESS1-0   CCAM-1704\"\n",
    "    , \"CNRM-CM5   CCAM-1704\"\n",
    "    , \"GFDL-ESM2M   CCAM-1704\"\n",
    "    , \"HadGEM2-CC   CCAM-1704\"\n",
    "    , \"MIROC5   CCAM-1704\"\n",
    "    , \"NorESM1-M   CCAM-1704\"\n",
    "    , \"ACCESS1-0   CCAM-2008\"\n",
    "    , \"CanESM2   CCAM-2008\"\n",
    "    , \"GFDL-ESM2M   CCAM-2008\"\n",
    "    , \"MIROC5   CCAM-2008\"\n",
    "    , \"HadGEM2-ES   CCLM5-0-15\"\n",
    "    , \"MPI-ESM-LR   CCLM5-0-15\"\n",
    "    , \"MPI-ESM-MR   RegCM4-7\"\n",
    "    , \"NorESM1-M   RegCM4-7\"\n",
    "    , \"HadGEM2-ES   REMO2015\"\n",
    "    , \"MPI-ESM-LR   REMO2015\"\n",
    "    , \"NorESM1-M   REMO2015\"\n",
    "    , \"ACCESS1-0   WRF360J\"\n",
    "    , \"CanESM2   WRF360J\"\n",
    "    , \"ACCESS1-0   WRF360K\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c067347-4c66-4ff2-81dd-425990f93491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot numbers where we want to plot x- and/or y-axis labels (this will need to be updated based on the number of datasets used)\n",
    "# 7 X 3 Plot\n",
    "y_label = [0,3,6,9,12,15]\n",
    "x_label = [19,20]\n",
    "both_label = [18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0188ac-41ff-4f65-b5c0-9344eedd328c",
   "metadata": {},
   "source": [
    "### Define colors to shade different categories of drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b495c1-68be-4aac-a4dd-ba7b170c28c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to find areas that need to be shaded using a boolean mask as input\n",
    "def fill_vertical_columns(boolean_fill_mask):\n",
    "    \n",
    "    # Find areas in the mask when values change (i.e. boolean switched from True to False and vice versa)\n",
    "    boolean_switch = np.diff(boolean_fill_mask)\n",
    "    \n",
    "    # Find start and end of sections where the boolean fill mask is True (places I want to shade)\n",
    "    region_to_shade, = boolean_switch.nonzero()\n",
    "    \n",
    "    # Handle edge cases where condition starts or ends with True\n",
    "    if boolean_fill_mask[0]:\n",
    "        region_to_shade = np.r_[0, region_to_shade]\n",
    "   \n",
    "    if boolean_fill_mask[-1]:\n",
    "        region_to_shade = np.r_[region_to_shade, len(boolean_fill_mask)]\n",
    "    \n",
    "    # Reshape the result into pairs of start/end indices\n",
    "    region_to_shade = region_to_shade.reshape((-1, 2))\n",
    "    \n",
    "    return region_to_shade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41a118-f45a-498c-b6fd-d4d16aedcc31",
   "metadata": {},
   "source": [
    "### 3-Month SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ea766-b5ae-4039-9779-906098019162",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define figure size\n",
    "fig = plt.figure(figsize=(17,18))\n",
    "fig.suptitle(' 3-Month SPI (1976-2005)', fontsize=16, y=0.92)\n",
    "\n",
    "# Setup axes for all subplots\n",
    "gs = gridspec.GridSpec(5,4,width_ratios=[1,1,1,1], height_ratios=[1,1,1,1,1])\n",
    "\n",
    "row_max = 4\n",
    "col_max = 3\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "axs = {}\n",
    "\n",
    "# Set up Axes labels (this loops through the sorted Pandas DF to assign axes positions based on largest slope)\n",
    "# For Models\n",
    "for dataset_name in dataset_names:\n",
    "    axs[f'{dataset_name}'] = fig.add_subplot(gs[row,col])\n",
    "    \n",
    "    if col == col_max:\n",
    "        row = row + 1\n",
    "        col = 0 \n",
    "    else:\n",
    "        col = col + 1\n",
    "\n",
    "# Add subplot titles\n",
    "for name, ax in axs.items():\n",
    "    ax.set_title(name, fontsize=13)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "time = obs_ts_dict['obs_3mon'].time.values\n",
    "year_loc = mdates.YearLocator(5)  # Set every 5 years\n",
    "year_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "# Add Data to Plots\n",
    "# AGCD\n",
    "axs['AGCD'].plot(time, obs_ts_dict['obs_3mon'].values.round(2), color='black', linestyle='-')\n",
    "\n",
    "# Models\n",
    "for model_name in model_3mon_ts_dict.keys():\n",
    "    axs[model_name].plot(time, model_3mon_ts_dict[model_name].values.round(2), color='black', linestyle='-')\n",
    "    \n",
    "# Set axis ticks for only left and bottom figures    \n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    if i in y_label:\n",
    "        ax.set_yticklabels([-2.5, -2.0, -1.0, 0, 1.0, 2.0])\n",
    "        ax.set_ylabel(\"SPI\", fontsize=12)\n",
    "    elif i in x_label:\n",
    "        ax.xaxis.set_major_locator(year_loc)\n",
    "        ax.xaxis.set_major_formatter(year_fmt)\n",
    "        ax.set_xlabel(\"year\", fontsize=11)\n",
    "    elif i in both_label:\n",
    "        ax.set_yticklabels([-2.5, 2.0, -1.0, 0, 1.0, 2.0])\n",
    "        ax.xaxis.set_major_locator(year_loc)\n",
    "        ax.xaxis.set_major_formatter(year_fmt)\n",
    "        ax.set_xlabel(\"year\", fontsize=11)\n",
    "        ax.set_ylabel(\"SPI\", fontsize=12)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "# Add Data to Plots\n",
    "# AGCD\n",
    "#axs['AGCD'].plot(time, obs_ts_dict['obs_3mon'].values, color='black', linestyle='-')\n",
    "\n",
    "# Models\n",
    "#for model_name in model_3mon_ts_dict.keys():\n",
    "#    axs[model_name].plot(time, model_3mon_ts_dict[model_name].values, color='black', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b49370-a1c1-475b-a367-809961ee3898",
   "metadata": {},
   "source": [
    "### 6-Month SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc71256-2b4a-4319-b6e3-eb1b71df1e21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define figure size\n",
    "fig = plt.figure(figsize=(17,18))\n",
    "fig.suptitle(' 6-Month SPI (1976-2005)', fontsize=16, y=0.92)\n",
    "\n",
    "# Setup axes for all subplots\n",
    "gs = gridspec.GridSpec(5,4,width_ratios=[1,1,1,1], height_ratios=[1,1,1,1,1])\n",
    "\n",
    "row_max = 4\n",
    "col_max = 3\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "axs = {}\n",
    "\n",
    "# Set up Axes labels (this loops through the sorted Pandas DF to assign axes positions based on largest slope)\n",
    "# For Models\n",
    "for dataset_name in dataset_names:\n",
    "    axs[f'{dataset_name}'] = fig.add_subplot(gs[row,col])\n",
    "    \n",
    "    if col == col_max:\n",
    "        row = row + 1\n",
    "        col = 0 \n",
    "    else:\n",
    "        col = col + 1\n",
    "\n",
    "# Add subplot titles\n",
    "for name, ax in axs.items():\n",
    "    ax.set_title(name, fontsize=13)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "time = obs_ts_dict['obs_6mon'].time.values\n",
    "year_loc = mdates.YearLocator(5)  # Set every 5 years\n",
    "year_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "# Add Data to Plots\n",
    "# AGCD\n",
    "axs['AGCD'].plot(time, obs_ts_dict['obs_6mon'].values.round(2), color='black', linestyle='-')\n",
    "\n",
    "# Models\n",
    "for model_name in model_6mon_ts_dict.keys():\n",
    "    axs[model_name].plot(time, model_6mon_ts_dict[model_name].values.round(2), color='black', linestyle='-')\n",
    "    \n",
    "# Set axis ticks for only left and bottom figures    \n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    if i in y_label:\n",
    "        ax.set_yticklabels([-2.5, -2.0, -1.0, 0, 1.0, 2.0])\n",
    "        ax.set_ylabel(\"SPI\", fontsize=12)\n",
    "    elif i in x_label:\n",
    "        ax.xaxis.set_major_locator(year_loc)\n",
    "        ax.xaxis.set_major_formatter(year_fmt)\n",
    "        ax.set_xlabel(\"year\", fontsize=11)\n",
    "    elif i in both_label:\n",
    "        ax.set_yticklabels([-2.5, 2.0, -1.0, 0, 1.0, 2.0])\n",
    "        ax.xaxis.set_major_locator(year_loc)\n",
    "        ax.xaxis.set_major_formatter(year_fmt)\n",
    "        ax.set_xlabel(\"year\", fontsize=11)\n",
    "        ax.set_ylabel(\"SPI\", fontsize=12)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04315741-1231-4901-8223-fdfb59aec8a6",
   "metadata": {},
   "source": [
    "### 12-Month SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f6a26-20a8-4b9f-8aea-0b58e38dc191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define figure size\n",
    "fig = plt.figure(figsize=(17,22))\n",
    "fig.suptitle(' 12-Month SPI (1976-2005)', fontsize=16, y=0.91)\n",
    "\n",
    "# Setup axes for all subplots\n",
    "gs = gridspec.GridSpec(7,3,width_ratios=[1.5,1.5,1.5], height_ratios=[0.8,0.8,0.8,0.8,0.8,0.8,0.8])\n",
    "\n",
    "row_max = 6\n",
    "col_max = 2\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "axs = {}\n",
    "\n",
    "# Set up Axes labels (this loops through the sorted Pandas DF to assign axes positions based on largest slope)\n",
    "# For Models\n",
    "for dataset_name in dataset_names_rcm_sorted:\n",
    "    axs[f'{dataset_name}'] = fig.add_subplot(gs[row,col])\n",
    "    \n",
    "    if col == col_max:\n",
    "        row = row + 1\n",
    "        col = 0 \n",
    "    else:\n",
    "        col = col + 1\n",
    "\n",
    "# Add subplot titles\n",
    "for name, ax in axs.items():\n",
    "    ax.set_title(name, fontsize=14)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "time = obs_ts_dict['obs_12mon'].time.values\n",
    "year_loc = mdates.YearLocator(5)  # Set every 5 years\n",
    "year_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "# Add Data to Plots\n",
    "# AGCD\n",
    "data = obs_ts_dict['obs_12mon'].values.round(2)\n",
    "\n",
    "# Plot time series and brown horizontal 0-line\n",
    "axs['AGCD'].plot(time, data, color='black', linestyle='-')\n",
    "axs['AGCD'].axhline(y=0, color='sienna', linestyle='-')\n",
    "\n",
    "# Add shading along time series for each category of drought\n",
    "# Create boolean masks for each drought category\n",
    "#no_drought_mask = data > mild_max\n",
    "#mild_mask = (data <= mild_max) & (data > mild_min)\n",
    "moderate_mask = (data <= moderate_max) & (data > moderate_min)\n",
    "severe_mask = (data <= severe_max) & (data > severe_min)\n",
    "extreme_mask = data <= extreme_max\n",
    "\n",
    "# Create vertical shaded regions for each drought category\n",
    "for ts_mask, color, label in zip([moderate_mask, severe_mask, extreme_mask], \n",
    "                              ['orange', 'crimson', 'darkred'],\n",
    "                              ['Moderate', 'Severe', 'Extreme']):\n",
    "    \n",
    "    # find contiguous regions where the mask is True\n",
    "    regions = fill_vertical_columns(ts_mask)\n",
    "    for start, end in regions:\n",
    "        # create shaded region for this contiguous region\n",
    "        axs['AGCD'].axvspan(time[start], time[end-1], color=color, alpha=0.2, label=label)\n",
    "\n",
    "\n",
    "# Models\n",
    "for model_name in model_12mon_ts_dict.keys():\n",
    "    \n",
    "    # Plot fussy models separately\n",
    "    if model_name in [\"MIROC5   CCAM-2008\", \"ACCESS1-0   WRF360K\"]:\n",
    "        data = model_12mon_ts_dict[model_name].values.round(2)\n",
    "        time = model_12mon_ts_dict[model_name]['time'].values.astype(\"datetime64[ns]\")\n",
    "        year_loc = mdates.YearLocator(5)  # Set every 5 years\n",
    "        year_fmt = mdates.DateFormatter('%Y')\n",
    "        \n",
    "    \n",
    "        # Plot time series and brown horizontal 0-line\n",
    "        axs[model_name].plot(time, data, color='black', linestyle='-')\n",
    "        axs[model_name].axhline(y=0, color='sienna', linestyle='-')\n",
    "        \n",
    "        # Add shading along the time series for each category of drought\n",
    "        # Create boolean masks for each drought category\n",
    "        no_drought_mask = data > moderate_max\n",
    "        #mild_mask = (data < mild_max) & (data > mild_min)\n",
    "        moderate_mask = (data <= moderate_max) & (data > moderate_min)\n",
    "        severe_mask = (data <= severe_max) & (data > severe_min)\n",
    "        extreme_mask = data <= extreme_max\n",
    "\n",
    "   \n",
    "        # create vertical shaded regions for each drought category\n",
    "        for ts_mask, color, label in zip([moderate_mask, severe_mask, extreme_mask], \n",
    "                                      ['orange', 'crimson', 'darkred'],\n",
    "                                      ['Moderate', 'Severe', 'Extreme']):\n",
    "    \n",
    "            # find contiguous regions where the mask is True\n",
    "            regions_fussy = fill_vertical_columns(ts_mask)\n",
    "            for start, end in regions_fussy:\n",
    "                if start == 0 & end == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    # create shaded region for this contiguous region\n",
    "                    axs[model_name].axvspan(time[start], time[end-1], color=color, alpha=0.2, label=label)\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        data = model_12mon_ts_dict[model_name].values.round(2)\n",
    "        time = model_12mon_ts_dict[model_name]['time'].values.astype(\"datetime64[ns]\")\n",
    "        year_loc = mdates.YearLocator(5)  # Set every 5 years\n",
    "        year_fmt = mdates.DateFormatter('%Y')\n",
    "        \n",
    "    \n",
    "        # Plot time series and brown horizontal 0-line\n",
    "        axs[model_name].plot(time, data, color='black', linestyle='-')\n",
    "        axs[model_name].axhline(y=0, color='sienna', linestyle='-')\n",
    "        \n",
    "        # Add shading along time series for each category of drought\n",
    "        # Create boolean masks for each drought category\n",
    "        #mild_mask = (data < mild_max) & (data > mild_min)\n",
    "        moderate_mask = (data <= moderate_max) & (data > moderate_min)\n",
    "        severe_mask = (data <= severe_max) & (data > severe_min)\n",
    "        extreme_mask = data <= extreme_max\n",
    "\n",
    "                \n",
    "        # create vertical shaded regions for each drought category\n",
    "        for ts_mask, color, label in zip([moderate_mask, severe_mask, extreme_mask], \n",
    "                                      ['orange', 'crimson', 'darkred'],\n",
    "                                      ['Moderate', 'Severe', 'Extreme']):\n",
    "    \n",
    "            # find contiguous regions where the mask is True\n",
    "            regions = fill_vertical_columns(ts_mask)\n",
    "            for start, end in regions:\n",
    "                # create shaded region for this contiguous region\n",
    "                axs[model_name].axvspan(time[start], time[end-1], color=color, alpha=0.2, label=label)\n",
    "        \n",
    "# Set axis ticks for only left and bottom figures    \n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([-2.5, -2.0, -1.0, 0, 1.0, 2.0])\n",
    "    if i in y_label:\n",
    "        #ax.set_yticklabels([-2.5, -2.0, -1.0, 0, 1.0, 2.0])\n",
    "        ax.set_ylabel(\"SPI\", fontsize=12)\n",
    "    elif i in x_label:\n",
    "        ax.xaxis.set_major_locator(year_loc)\n",
    "        ax.xaxis.set_major_formatter(year_fmt)\n",
    "        ax.set_xlabel(\"year\", fontsize=11)\n",
    "    elif i in both_label:\n",
    "        #ax.set_yticklabels([-2.5, -2.0, -1.0, 0, 1.0, 2.0])\n",
    "        ax.xaxis.set_major_locator(year_loc)\n",
    "        ax.xaxis.set_major_formatter(year_fmt)\n",
    "        ax.set_xlabel(\"year\", fontsize=11)\n",
    "        ax.set_ylabel(\"SPI\", fontsize=12)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "plt.gcf().text(0.36, 0.08, \"Drought Categories: \", rotation='horizontal', fontsize=12, color='black', weight='bold')\n",
    "#plt.gcf().text(0.47, 0.08, \"Mild\", rotation='horizontal', fontsize=10, color='gold', weight='bold')\n",
    "plt.gcf().text(0.48, 0.08, \"Moderate\", rotation='horizontal', fontsize=12, color='darkorange', weight='bold')\n",
    "plt.gcf().text(0.55, 0.08, \"Severe\", rotation='horizontal', fontsize=12, color='crimson', weight='bold')\n",
    "plt.gcf().text(0.61, 0.08, \"Extreme\", rotation='horizontal', fontsize=12, color=\"darkred\", weight='bold')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
